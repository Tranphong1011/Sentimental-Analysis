{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac40ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c2993b",
   "metadata": {},
   "source": [
    "### Import dữ liệu sau processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc61989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDRestaurant</th>\n",
       "      <th>Comment_new</th>\n",
       "      <th>rating_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>chiên sống</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ngon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>thừa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>kêu đói háo_hức thành khóc ròng khóc ròng khóc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tặng uống</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>thề lắm tức_giận mừng háo_hức khô chú_ý minion...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>thử hơi kén không_ngon_miệng dập tắt nghiện cư...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>kết_hợp không_thấy không_cung_cấp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>dở ăn_tây tây ngon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>cười</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IDRestaurant                                        Comment_new  \\\n",
       "0             1                                         chiên sống   \n",
       "1             1                                               ngon   \n",
       "2             1                                               thừa   \n",
       "3             1  kêu đói háo_hức thành khóc ròng khóc ròng khóc...   \n",
       "4             1                                          tặng uống   \n",
       "5             1  thề lắm tức_giận mừng háo_hức khô chú_ý minion...   \n",
       "6             1  thử hơi kén không_ngon_miệng dập tắt nghiện cư...   \n",
       "7             1                  kết_hợp không_thấy không_cung_cấp   \n",
       "8             1                                 dở ăn_tây tây ngon   \n",
       "9             1                                               cười   \n",
       "\n",
       "   rating_encoded  \n",
       "0               1  \n",
       "1               1  \n",
       "2               0  \n",
       "3               1  \n",
       "4               2  \n",
       "5               0  \n",
       "6               2  \n",
       "7               0  \n",
       "8               1  \n",
       "9               0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Reviews_preprocessed.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bded31",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b193df24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    22094\n",
       "1     4116\n",
       "0     3707\n",
       "Name: rating_encoded, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating_encoded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "822c56e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               chiên sống\n",
       "1                                                     ngon\n",
       "2                                                     thừa\n",
       "3        kêu đói háo_hức thành khóc ròng khóc ròng khóc...\n",
       "4                                                tặng uống\n",
       "                               ...                        \n",
       "29912          ngon skdkdjabgkflagshjxjozn bzokzbzjznb đào\n",
       "29913                                                  góp\n",
       "29914    lừa mong rửa_kỉ điện_thoại đừng phá nuôi lừa c...\n",
       "29915                                         ngon sạch_sẽ\n",
       "29916                                              dạy đắt\n",
       "Name: Comment_new, Length: 29917, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = df['Comment_new']\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac534019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        1\n",
       "4        2\n",
       "        ..\n",
       "29912    2\n",
       "29913    2\n",
       "29914    0\n",
       "29915    2\n",
       "29916    0\n",
       "Name: rating_encoded, Length: 29917, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df['rating_encoded']\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "844846f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['chiên sống', 'ngon', 'thừa', ...,\n",
       "       'lừa mong rửa_kỉ điện_thoại đừng phá nuôi lừa chụp hình_ảnh tắt xào cải_ngọt',\n",
       "       'ngon sạch_sẽ', 'dạy đắt'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = np.array(source)\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfc86991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data = np.array(target)\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "721cfe0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<29917x27609 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 332713 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer()\n",
    "count.fit(text_data)\n",
    "bag_of_words = count.transform(text_data)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a909b52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=bag_of_words.toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f443f0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29917, 27609)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7428f41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = target_data\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb90a1",
   "metadata": {},
   "source": [
    "### Split data into train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be5d1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0953e2d0",
   "metadata": {},
   "source": [
    "### Select model : Chọn model Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11e12c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b706c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22395072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score Scikit learn - train:  0.844106463878327\n"
     ]
    }
   ],
   "source": [
    "print('score Scikit learn - train: ', model.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a071a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score Scikit learn:  0.7962901069518716\n"
     ]
    }
   ],
   "source": [
    "print('score Scikit learn: ', model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2df5b213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  79.62901069518716 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy is \", accuracy_score(y_test,y_pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d28bdbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.53      0.60       734\n",
      "           1       0.42      0.08      0.14       846\n",
      "           2       0.82      0.98      0.89      4404\n",
      "\n",
      "    accuracy                           0.80      5984\n",
      "   macro avg       0.65      0.53      0.54      5984\n",
      "weighted avg       0.75      0.80      0.75      5984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff6df1",
   "metadata": {},
   "source": [
    "Nhận xét:\n",
    "Mô hình  có accuracy tổng thể là 0.80, với các chỉ số precision và recall khác nhau đối với từng lớp. Lớp positive (2) có hiệu suất tốt nhất với precision và recall lần lượt là 0.82 và 0.98, trong khi lớp neutral (1) có hiệu suất thấp nhất với precision và recall với chỉ 0.42 và 0.08. Điều này chứng tỏ rằng mô hình gặp khó khăn trong việc phân loại các đánh giá là neutral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85a753da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import pickle\n",
    "filename = 'Naive_Bayes_models_MDS6.pkl'\n",
    "\n",
    "# Save the model to a file using pickle\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d4e934",
   "metadata": {},
   "source": [
    "### Người dùng cuối muốn biết rating thuộc nhóm nào dựa vào review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72ba5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickledel from the file\n",
    "import pickle\n",
    "with open(\"Naive_Bayes_models_MDS6.pkl\", 'rb') as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3d1e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature engineering pipeline \n",
    "def feature_engineering_pipeline(text):\n",
    "    new_text_data = np.append(text_data,text)\n",
    "    new_bag_of_words = count.transform(new_text_data).toarray()\n",
    "    last_text_2d = new_bag_of_words[-1].reshape(1, -1)\n",
    "    rating_predicted = loaded_model.predict(last_text_2d)\n",
    "    return rating_predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18d8beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rating dictionary:\n",
    "rating_code = {\n",
    "    0: \"negative\",\n",
    "    1: \"neutral\",\n",
    "    2: \"positive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1caf350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bạn hãy cho bình luận về một nhà hàng nào đó: Nhà hàng này trên cả tuyệt vời. Đồ ăn tươi ngon\n",
      "Text after process:  tươi ngon\n",
      "Rating:  positive\n"
     ]
    }
   ],
   "source": [
    "# Load data process pipeline:\n",
    "import Data_processing_pipeline\n",
    "text = input(\"Bạn hãy cho bình luận về một nhà hàng nào đó: \")\n",
    "text_after_process = Data_processing_pipeline.text_processing_pipeline(text)\n",
    "print(\"Text after process: \", text_after_process)\n",
    "print(\"Rating: \", rating_code[feature_engineering_pipeline(text_after_process)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d6e79",
   "metadata": {},
   "source": [
    "### Propose model : Chọn model Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "762e6f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8158422459893048\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_cleaned = df.dropna(subset=['Comment_new'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(df_cleaned['Comment_new'], df_cleaned['rating_encoded'], test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_svm.astype(str))\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_svm.astype(str))\n",
    "\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Train the classifier\n",
    "svm_classifier.fit(X_train_tfidf, y_train_svm)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_svm, y_pred_svm)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5d117d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65       717\n",
      "           1       0.52      0.05      0.10       811\n",
      "           2       0.84      0.98      0.91      4456\n",
      "\n",
      "    accuracy                           0.82      5984\n",
      "   macro avg       0.67      0.56      0.55      5984\n",
      "weighted avg       0.78      0.82      0.77      5984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_svm, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96afba72",
   "metadata": {},
   "source": [
    "Nhận xét: Mô hình SVM có acc nhiều hơn so với NavieBays 2 %, không có thay đổi đáng kể. Mô hình SVM vẫn gặp khó khăn trong việc phân loại các đánh giá là neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9b064c",
   "metadata": {},
   "source": [
    "### Handle imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d922bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn\n",
    "# !pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7c97e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imbalanced-learn version: 0.12.0\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "\n",
    "print(\"imbalanced-learn version:\", imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c83828eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "475c06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5ce696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 17690 samples\n",
      "Class 1: 17690 samples\n",
      "Class 2: 17690 samples\n"
     ]
    }
   ],
   "source": [
    "# y_resampled.value_counts()\n",
    "unique_elements, counts = np.unique(y_resampled, return_counts=True)\n",
    "\n",
    "# Print the value counts\n",
    "for label, count in zip(unique_elements, counts):\n",
    "    print(f\"Class {label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91fd2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "model = clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19fefff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 529  106   99]\n",
      " [ 205  285  356]\n",
      " [ 153  666 3585]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.65       734\n",
      "           1       0.27      0.34      0.30       846\n",
      "           2       0.89      0.81      0.85      4404\n",
      "\n",
      "    accuracy                           0.74      5984\n",
      "   macro avg       0.58      0.62      0.60      5984\n",
      "weighted avg       0.76      0.74      0.75      5984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4308f",
   "metadata": {},
   "source": [
    "### Nhận xét: Accuracy giảm hơn so với khi chưa resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c283c0a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Tạo dữ liệu giả không chính xác: SMOTE tạo ra các mẫu dữ liệu mới bằng cách nội suy giữa các điểm dữ liệu hiện có. Tuy nhiên, quá trình nội suy này có thể tạo ra các mẫu dữ liệu không chính xác hoặc không đại diện cho tập dữ liệu thực tế. Điều này dẫn đến model học các mẫu sai và giảm độ chính xác khi dự đoán.\n",
    "\n",
    "2. Vấn đề overfitting: SMOhể dẫn đến overfitting, đặc biệt khi tập dữ liệu ban đặc không cân bằng. Khi SMOTE tạo ra nhiều mẫu dữ liệu cho lớp thiểu số, model có thể học các đặc điểm cụ thể của các mẫu dữ liệu giả này thay vì học các đặc điểm chung của lớp thiểu số. Điều nhể dẫn đến model hoạt động tốt trên tập dữ liệu huấn luyện nhưng kém trên tập dữ liệu thử nghiệm.\n",
    "\n",
    "3. Tăng nhiễu dữ liệu: S thể làm tăng nhiễu trong tập dữ  hợp. Việc thêm nhiễu vào dữ l thể khiến model khó học các mẫu chính xác và làm giảm độ chính xác."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
